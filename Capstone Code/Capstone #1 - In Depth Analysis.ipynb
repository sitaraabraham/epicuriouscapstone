{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import normaltest\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.stats import weightstats as stests\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "sns.set(style=\"whitegrid\", palette=\"pastel\", color_codes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Link to Dataset: https://www.kaggle.com/hugodarwood/epirecipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../cleaned_epi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>rating</th>\n",
       "      <th>calories</th>\n",
       "      <th>protein</th>\n",
       "      <th>fat</th>\n",
       "      <th>sodium</th>\n",
       "      <th>appetizer</th>\n",
       "      <th>dessert</th>\n",
       "      <th>dinner</th>\n",
       "      <th>low carb</th>\n",
       "      <th>low sugar</th>\n",
       "      <th>meat</th>\n",
       "      <th>vegan</th>\n",
       "      <th>vegetarian</th>\n",
       "      <th>snack</th>\n",
       "      <th>alcoholic</th>\n",
       "      <th>holidays</th>\n",
       "      <th>SqrtCalories</th>\n",
       "      <th>LogProtein</th>\n",
       "      <th>SqrtFat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Boudin Blanc Terrine with Red Onion Confit</td>\n",
       "      <td>4.375</td>\n",
       "      <td>403.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1439.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.07486</td>\n",
       "      <td>2.944439</td>\n",
       "      <td>4.795832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         title  rating  calories  protein  \\\n",
       "0  Boudin Blanc Terrine with Red Onion Confit    4.375     403.0     18.0   \n",
       "\n",
       "    fat  sodium  appetizer  dessert  dinner  low carb  low sugar  meat  vegan  \\\n",
       "0  23.0  1439.0        0.0      0.0     0.0       0.0        0.0   0.0    0.0   \n",
       "\n",
       "   vegetarian  snack  alcoholic  holidays  SqrtCalories  LogProtein   SqrtFat  \n",
       "0         0.0    0.0        0.0         1      20.07486    2.944439  4.795832  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.drop(columns='title',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.375    5419\n",
       "3.750    3530\n",
       "5.000    1745\n",
       "3.125    1019\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rating.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating          float64\n",
       "calories        float64\n",
       "protein         float64\n",
       "fat             float64\n",
       "sodium          float64\n",
       "appetizer       float64\n",
       "dessert         float64\n",
       "dinner          float64\n",
       "low carb        float64\n",
       "low sugar       float64\n",
       "meat            float64\n",
       "vegan           float64\n",
       "vegetarian      float64\n",
       "snack           float64\n",
       "alcoholic       float64\n",
       "holidays          int64\n",
       "SqrtCalories    float64\n",
       "LogProtein      float64\n",
       "SqrtFat         float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create feature and target variables\n",
    "X = df[['calories','protein','fat','vegetarian','holidays','sodium']]\n",
    "y = df['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1) # 80% training and 20% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_enc = preprocessing.LabelEncoder()\n",
    "ytrain_enc = lab_enc.fit_transform(y_train)\n",
    "ytest_enc = lab_enc.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Decision Tree classifer object\n",
    "clf = DecisionTreeClassifier(criterion=\"gini\")\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(X_train,ytrain_enc)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred_enc = lab_enc.fit_transform(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.43491250533504056\n"
     ]
    }
   ],
   "source": [
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(ytest_enc, ypred_enc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This accuracy score is on the lower end, it could be improved by tuning the hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "lab_enc = preprocessing.LabelEncoder()\n",
    "y_enc = lab_enc.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarize the output\n",
    "y = label_binarize(y_enc, classes=[0,1,2,3])\n",
    "n_classes = y.shape[1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1) # 80% training and 20% test\n",
    "\n",
    "clf = DecisionTreeClassifier(criterion=\"gini\")\n",
    "\n",
    "clf = clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_pred[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_pred.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6250533504054632\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc['micro'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.23      0.26      0.24       206\n",
      "          1       0.40      0.40      0.40       706\n",
      "          2       0.52      0.54      0.53      1026\n",
      "          3       0.39      0.34      0.37       405\n",
      "\n",
      "avg / total       0.44      0.44      0.44      2343\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Decision Tree classifer object\n",
    "clf = DecisionTreeClassifier(criterion=\"entropy\")\n",
    "\n",
    "clf = clf.fit(X_train,ytrain_enc)\n",
    "\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred_enc = lab_enc.fit_transform(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.42168160478019634\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(ytest_enc, ypred_enc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy decreased with the criterion change, so we will keep the criterion as \"gini.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Max Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# redefine X and y\n",
    "X = df[['calories','protein','fat','vegetarian','holidays','sodium']]\n",
    "y = df['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_enc = preprocessing.LabelEncoder()\n",
    "y_enc = lab_enc.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_enc, test_size=0.2, random_state=1) \n",
    "# 80% training and 20% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depths = np.linspace(1, 32, 32, endpoint=True)\n",
    "scores = []\n",
    "for max_depth in max_depths:\n",
    "    clf = DecisionTreeClassifier(max_depth=max_depth)\n",
    "    clf = clf.fit(X_train,y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    ypred_enc = lab_enc.fit_transform(y_pred)\n",
    "    scores.append(metrics.accuracy_score(y_test,ypred_enc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Maximum Depth:  2.0\n"
     ]
    }
   ],
   "source": [
    "best_max_depth = max_depths[scores.index(max(scores))]\n",
    "print('Best Maximum Depth: ',best_max_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimum Sample Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# redefine X and y\n",
    "X = df[['calories','protein','fat','vegetarian','holidays','sodium']]\n",
    "y = df['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_enc = preprocessing.LabelEncoder()\n",
    "y_enc = lab_enc.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_enc, test_size=0.2, random_state=1) \n",
    "# 80% training and 20% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_samples_splits = np.linspace(0.1, 1.0, 10, endpoint=True)\n",
    "scores = []\n",
    "for min_split in min_samples_splits:\n",
    "    clf = DecisionTreeClassifier(min_samples_split=min_split)\n",
    "    clf = clf.fit(X_train,y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    ypred_enc = lab_enc.fit_transform(y_pred)\n",
    "    scores.append(metrics.accuracy_score(y_test,ypred_enc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Minimum Sample Split:  0.2\n"
     ]
    }
   ],
   "source": [
    "best_min_split = min_samples_splits[scores.index(max(scores))]\n",
    "print('Best Minimum Sample Split: ',best_min_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimum Samples Leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# redefine X and y\n",
    "X = df[['calories','protein','fat','vegetarian','holidays','sodium']]\n",
    "y = df['rating']\n",
    "\n",
    "lab_enc = preprocessing.LabelEncoder()\n",
    "y_enc = lab_enc.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_enc, test_size=0.2, random_state=1) \n",
    "# 80% training and 20% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_samples_leaf = np.linspace(0.1, 0.5, 5, endpoint=True)\n",
    "scores = []\n",
    "for leaf in min_samples_leaf:\n",
    "    clf = DecisionTreeClassifier(min_samples_leaf=leaf)\n",
    "    clf = clf.fit(X_train,y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    ypred_enc = lab_enc.fit_transform(y_pred)\n",
    "    scores.append(metrics.accuracy_score(y_test,ypred_enc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Minimum Sample Leaf:  0.1\n"
     ]
    }
   ],
   "source": [
    "best_min_leaf = min_samples_leaf[scores.index(max(scores))]\n",
    "print('Best Minimum Sample Leaf: ',best_min_leaf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Tuning - CV Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# redefine X and y\n",
    "X = df[['calories','protein','fat','vegetarian','holidays','sodium']]\n",
    "y = df['rating']\n",
    "\n",
    "lab_enc = preprocessing.LabelEncoder()\n",
    "y_enc = lab_enc.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_enc, test_size=0.2, random_state=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the hyperparameter grid\n",
    "max_depths = np.linspace(1, 32, 32, endpoint=True)\n",
    "min_samples_splits = np.linspace(0.1, 1.0, 10, endpoint=True)\n",
    "min_samples_leaf = [0.001, 0.1, 1, 10, 100]\n",
    "criterion = ['gini','entropy']\n",
    "param_grid = {'criterion': criterion,'max_depth': max_depths,'min_samples_split': min_samples_splits, \n",
    "              'min_samples_leaf': min_samples_leaf}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine parameters with model\n",
    "clf_model = GridSearchCV(clf,param_grid,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'criterion': ['gini', 'entropy'], 'max_depth': array([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,\n",
       "       14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25., 26.,\n",
       "       27., 28., 29., 30., 31., 32.]), 'min_samples_split': array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]), 'min_samples_leaf': [0.001, 0.1, 1, 10, 100]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit it to the data\n",
    "clf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Logistic Regression Parameters: {'criterion': 'gini', 'max_depth': 4.0, 'min_samples_leaf': 0.001, 'min_samples_split': 0.2}\n",
      "Test Data Accuracy Score:  0.4379001280409731\n"
     ]
    }
   ],
   "source": [
    "# Print the tuned parameter and score\n",
    "print(\"Tuned Logistic Regression Parameters: {}\".format(clf_model.best_params_))\n",
    "print('Test Data Accuracy Score: ',accuracy_score(clf_model.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred_enc = lab_enc.fit_transform(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       206\n",
      "          1       0.00      0.00      0.00       706\n",
      "          2       0.44      1.00      0.61      1026\n",
      "          3       0.00      0.00      0.00       405\n",
      "\n",
      "avg / total       0.19      0.44      0.27      2343\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we will use PCA to reduce the dimensions to the 2 most important in predicting a rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['calories','protein','fat','vegetarian','holidays','sodium']]\n",
    "y = df['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import PCA\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Create a PCA model with 2 components: pca\n",
    "pca = PCA(n_components = 2)\n",
    "\n",
    "# Fit the PCA instance to tX\n",
    "pca.fit(X)\n",
    "\n",
    "# Transform the scaled samples: pca_features\n",
    "X = pca.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_enc = preprocessing.LabelEncoder()\n",
    "y_enc = lab_enc.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_enc, test_size=0.2, random_state=1) \n",
    "# 80% training and 20% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Decision Tree classifer object with best parameter values\n",
    "clf = DecisionTreeClassifier(max_depth = 4.0, min_samples_leaf = 0.001, min_samples_split = 0.2)\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(X_train, ytrain_enc)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred_enc = lab_enc.fit_transform(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3013230900554844\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, ypred_enc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['calories','protein','fat','vegetarian','holidays','sodium']]\n",
    "y = df['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_enc = preprocessing.LabelEncoder()\n",
    "y_enc = lab_enc.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_enc, test_size=0.2, random_state=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "regressor = RandomForestClassifier(n_estimators=100, random_state=1)  \n",
    "regressor.fit(X_train, y_train)  \n",
    "y_pred = regressor.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred_enc = lab_enc.fit_transform(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 34  60 103   9]\n",
      " [  5 267 400  34]\n",
      " [  6 216 757  47]\n",
      " [  5  59 227 114]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.17      0.27       206\n",
      "          1       0.44      0.38      0.41       706\n",
      "          2       0.51      0.74      0.60      1026\n",
      "          3       0.56      0.28      0.37       405\n",
      "\n",
      "avg / total       0.51      0.50      0.47      2343\n",
      "\n",
      "0.5002134016218523\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(ytest_enc,ypred_enc))  \n",
    "print(classification_report(ytest_enc,ypred_enc))  \n",
    "print(accuracy_score(ytest_enc, ypred_enc))  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
